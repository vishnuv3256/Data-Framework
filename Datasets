import pandas as pd # type: ignore
import numpy as np # type: ignore
from faker import Faker # type: ignore
import random

# Initialize Faker for generating synthetic data
fake = Faker()

# Function to generate synthetic data
def generate_synthetic_data(n=100):
    data = []
    for _ in range(n):
        # Generate random data for name, address, email, age, and salary
        data.append({
            'Name': fake.name(),
            'Address': fake.address(),
            'Email': fake.email(),
            'Age': random.randint(18, 80),
            'Salary': round(random.uniform(30000, 120000), 2),
            'JoinDate': fake.date_this_decade()
        })
    df = pd.DataFrame(data)
    return df

# Function to check data quality
def check_data_quality(df):
    quality_report = {}

    # Check for missing values
    quality_report['Missing Values'] = df.isnull().sum().to_dict()

    # Check for duplicates
    quality_report['Duplicate Rows'] = df.duplicated().sum()

    # Check for outliers in the 'Salary' column using IQR method
    Q1 = df['Salary'].quantile(0.25)
    Q3 = df['Salary'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df['Salary'] < lower_bound) | (df['Salary'] > upper_bound)]
    quality_report['Outliers in Salary'] = len(outliers)

    return quality_report

# Generate synthetic data
df = generate_synthetic_data(200)

# Check the data quality
quality_report = check_data_quality(df)

# Output the results
print("Data Quality Report:")
for key, value in quality_report.items():
    print(f"{key}: {value}")

# Show the first few rows of the generated data
print("\nSample Data:")
print(df.head())
